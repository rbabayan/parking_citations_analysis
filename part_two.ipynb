{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import time\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read data and connect to database\n",
    "\n",
    "# Read data from Pandas \n",
    "def read_data_pandas():\n",
    "    start_time = time.time()\n",
    "    df = pandas.read_csv(\"dataset.csv\", low_memory=False)\n",
    "    end_time = time.time()\n",
    "    return df, end_time - start_time\n",
    "\n",
    "# Create SQLite client\n",
    "def connect_database():\n",
    "    start_time = time.time()\n",
    "    conn = sqlite3.connect('dataset.db')\n",
    "    end_time = time.time()\n",
    "    return conn, end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading dataset.csv into Pandas data frame...\n",
      "Time to load CSV dataset to Pandas: %s seconds 38.25836706161499\n",
      "\n",
      "Connecting SQLite client to dataset.db...\n",
      "Time to connect to SQLite database: %s seconds 0.005471229553222656\n"
     ]
    }
   ],
   "source": [
    "# Reading data and connecting to database:\n",
    "print(\"\\nReading dataset.csv into Pandas data frame...\")\n",
    "df,t = read_data_pandas()\n",
    "print(\"Time to load CSV dataset to Pandas: %s seconds\", t)\n",
    "print(\"\\nConnecting SQLite client to dataset.db...\")\n",
    "conn,t = connect_database()\n",
    "print(\"Time to connect to SQLite database: %s seconds\", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas copies all data over to memory and to a Data Frame format. On the other hand, SQLite keeps the data in disk and queries using a client.  Data transfer to memory, depending on the size of the data, can take significantly more time than keeping data in a database. \n",
    "\n",
    "For running ad-hoc queries; it is often more practical to keep data in a database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4357544"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where Make is NaN\n",
    "# Pandas: \n",
    "df = df[~df[\"Make\"].isna()]\n",
    "df[\"Make\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete rows where Make is empty\n",
    "# SQLite:\n",
    "conn.cursor().execute('DELETE FROM citations WHERE Make == \"\"')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Executions:\n",
      "SQLite Query run 1: 2.469014883041382 seconds\n",
      "Pandas Query run 1: 0.406688928604126 seconds\n",
      "SQLite Query run 2: 2.582409143447876 seconds\n",
      "Pandas Query run 2: 0.3519001007080078 seconds\n",
      "SQLite Query run 3: 2.900399923324585 seconds\n",
      "Pandas Query run 3: 0.37567830085754395 seconds\n",
      "-----------------\n",
      "Average run time:\n",
      "SQLite: 2.6506079832712808\n",
      "Pandas: 0.37808911005655926\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query a) calculate top 25 most common 'makes'\n",
    "\n",
    "# Using Pandas:\n",
    "def query_a_pandas(df, print_result=False):\n",
    "    start_time = time.time()\n",
    "    rows = df['Make'].value_counts()[:25].index.tolist()    \n",
    "    end_time = time.time()\n",
    "    if(print_result):\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "    return end_time - start_time\n",
    "\n",
    "# Using SQLite:\n",
    "def query_a_sqlite(conn, print_result=False):\n",
    "    start_time = time.time()\n",
    "    cursor = conn.execute('SELECT Make, count(*) as number_of_citations FROM citations GROUP BY Make ORDER BY number_of_citations DESC LIMIT 25')\n",
    "    rows = cursor.fetchall()\n",
    "    end_time = time.time()\n",
    "    if(print_result):\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "    return end_time - start_time\n",
    "\n",
    "print(\"Query Executions:\")\n",
    "exe_times_sqlite=[]\n",
    "exe_times_pandas=[]\n",
    "for i in range(3):\n",
    "    ts = query_a_sqlite(conn)\n",
    "    tp = query_a_pandas(df)\n",
    "    exe_times_sqlite.append(ts)\n",
    "    exe_times_pandas.append(tp)\n",
    "    print(\"SQLite Query run \"+str(i+1)+\": \"+str(ts)+\" seconds\")\n",
    "    print(\"Pandas Query run \"+str(i+1)+\": \"+str(tp)+\" seconds\")\n",
    "print(\"-----------------\")\n",
    "print(\"Average run time:\")\n",
    "print(\"SQLite: \"+str(sum(exe_times_sqlite)/len(exe_times_sqlite)))\n",
    "print(\"Pandas: \"+str(sum(exe_times_pandas)/len(exe_times_pandas)))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Executions:\n",
      "SQLite Query run 1: 4.300311088562012 seconds\n",
      "Pandas Query run 1: 4.417699813842773 seconds\n",
      "SQLite Query run 2: 5.368381023406982 seconds\n",
      "Pandas Query run 2: 1.9101898670196533 seconds\n",
      "SQLite Query run 3: 5.2095417976379395 seconds\n",
      "Pandas Query run 3: 2.0750911235809326 seconds\n",
      "-----------------\n",
      "Average run time:\n",
      "SQLite: 4.9594113032023115\n",
      "Pandas: 2.8009936014811196\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query b) calculate most common 'Color' for each 'Make'\n",
    "\n",
    "# Using Pandas:\n",
    "def query_b_pandas(df, print_result=False):\n",
    "    start_time = time.time()\n",
    "    df = df.dropna(subset=['Color'])\n",
    "    rows = df.groupby(['Make'])['Color'].agg(lambda x: pandas.Series.mode(x)[0]).to_dict()\n",
    "    end_time = time.time()\n",
    "    if(print_result):\n",
    "        for row in rows:\n",
    "            print(row, rows[row])            \n",
    "    return end_time - start_time\n",
    "\n",
    "# Using SQLite:\n",
    "def query_b_sqlite(conn, print_result=False):\n",
    "    start_time = time.time()\n",
    "    cursor = conn.execute('''\n",
    "        SELECT Make, Color FROM (\n",
    "            SELECT \n",
    "                ROW_NUMBER() OVER(PARTITION BY Make) AS RowNumber,\n",
    "                Make, \n",
    "                Color, \n",
    "                count(*) as number_of_citations \n",
    "            FROM \n",
    "                citations \n",
    "            WHERE \n",
    "                Color != \"\" \n",
    "            GROUP BY \n",
    "                Make, \n",
    "                Color \n",
    "            ORDER BY \n",
    "                Make, \n",
    "                number_of_citations DESC, \n",
    "                Color) as A \n",
    "        WHERE RowNumber = 1\n",
    "    ''')\n",
    "    rows = cursor.fetchall()\n",
    "    end_time = time.time()\n",
    "    if(print_result):\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "    return end_time - start_time\n",
    "\n",
    "print(\"Query Executions:\")\n",
    "exe_times_sqlite=[]\n",
    "exe_times_pandas=[]\n",
    "for i in range(3):\n",
    "    ts = query_b_sqlite(conn)\n",
    "    tp = query_b_pandas(df)\n",
    "    exe_times_sqlite.append(ts)\n",
    "    exe_times_pandas.append(tp)\n",
    "    print(\"SQLite Query run \"+str(i+1)+\": \"+str(ts)+\" seconds\")\n",
    "    print(\"Pandas Query run \"+str(i+1)+\": \"+str(tp)+\" seconds\")\n",
    "print(\"-----------------\")\n",
    "print(\"Average run time:\")\n",
    "print(\"SQLite: \"+str(sum(exe_times_sqlite)/len(exe_times_sqlite)))\n",
    "print(\"Pandas: \"+str(sum(exe_times_pandas)/len(exe_times_pandas)))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Executions:\n",
      "SQLite Query run 1: 3.2358012199401855 seconds\n",
      "Pandas Query run 1: 5.491661071777344 seconds\n",
      "SQLite Query run 2: 3.4396870136260986 seconds\n",
      "Pandas Query run 2: 1.8667690753936768 seconds\n",
      "SQLite Query run 3: 2.852605104446411 seconds\n",
      "Pandas Query run 3: 1.7528140544891357 seconds\n",
      "-----------------\n",
      "Average run time:\n",
      "SQLite: 3.1760311126708984\n",
      "Pandas: 3.0370814005533853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query c) find the first ticket issued for each 'Make'\n",
    "\n",
    "# Using Pandas\n",
    "def query_c_pandas(df, print_result=False):\n",
    "    start_time = time.time()\n",
    "    df = df.dropna(subset=['Issue Date'])\n",
    "    rows = df.groupby('Make')['Issue Date'].agg('min').to_dict()\n",
    "    end_time = time.time()\n",
    "    if(print_result):\n",
    "        for row in rows:\n",
    "            print(row, rows[row])\n",
    "    return end_time - start_time\n",
    "\n",
    "# Using SQLite\n",
    "def query_c_sqlite(conn, print_result=False):\n",
    "    start_time = time.time()\n",
    "    cursor = conn.execute('Select Make, min(\"Issue Date\") from citations group by Make')\n",
    "    rows = cursor.fetchall()\n",
    "    end_time = time.time()\n",
    "    if(print_result):\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "    return end_time - start_time\n",
    "\n",
    "print(\"Query Executions:\")\n",
    "exe_times_sqlite=[]\n",
    "exe_times_pandas=[]\n",
    "for i in range(3):\n",
    "    ts = query_c_sqlite(conn)\n",
    "    tp = query_c_pandas(df)\n",
    "    exe_times_sqlite.append(ts)\n",
    "    exe_times_pandas.append(tp)\n",
    "    print(\"SQLite Query run \"+str(i+1)+\": \"+str(ts)+\" seconds\")\n",
    "    print(\"Pandas Query run \"+str(i+1)+\": \"+str(tp)+\" seconds\")\n",
    "print(\"-----------------\")\n",
    "print(\"Average run time:\")\n",
    "print(\"SQLite: \"+str(sum(exe_times_sqlite)/len(exe_times_sqlite)))\n",
    "print(\"Pandas: \"+str(sum(exe_times_pandas)/len(exe_times_pandas)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas vs. SQLite (Run Time)\n",
    "There are two components involved: Loading Data, Running Queries\n",
    "Loading Data: \n",
    "As stated above, Panda loads data in memory. Depending on the size of the data this may take a long time. However, connecting to database that stores data in disk is almost instant.\n",
    "Running Queries: \n",
    "Panda's ability to keep data in Memory means fast queries. Data indexing in Pandas is not as efficient as a SQL based database like SQLite. Despite that, we still see Pandas queries run faster than SQL.\n",
    "Conclusion: \n",
    "Running ad-hoc queries are probably more efficient in SQL as we do not have to load the entire dataset in Memory. \n",
    "For an always running server that has the data loaded in memory, Pandas seems to be faster in response time. It is also important to note that the performance of the SQL queries depends largely on the I/O power of the computer where they are running.\n",
    "\n",
    "Ease of Use\n",
    "Both SQL and Pandas are powerful, well documented, and popular technologies that can address a wide range of query types. Pandas keep data formats close to Python data types which make it a little bit easier for a developer to handle. However, generally speaking, they are both easy technologies to query large datasets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading formatted geocoded file...\n",
      "California\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Second Question: \n",
    "# Is an out-of-state license plate more likely to be expired at the time of recieving a \n",
    "# ticket than an in-state license plate?\n",
    "\n",
    "# It appears that the dataset is from the state of California. \n",
    "# If this assumption turned out to be wrong, we could use the following \n",
    "# library to get the state where the citation was given using the\n",
    "# coordinates recorded at the time of citations. \n",
    "# This will take hours, if not days, to get the state for all data. \n",
    "\n",
    "import reverse_geocoder as rg\n",
    "coordinates = (37.38605,-122.08385) #just an example for the sake of demo\n",
    "results = rg.search(coordinates) \n",
    "print(results[0]['admin1'])\n",
    "\n",
    "# To save time this exercise assumes all citations occured in California"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of out of state cars that received a citation while their license plate was expired:\n",
      "23.49205627656431\n"
     ]
    }
   ],
   "source": [
    "# Separate out of state autos from CA autos\n",
    "non_ca_cars = df[df['RP State Plate'] != 'CA']\n",
    "# Drop extra columns\n",
    "non_ca_cars = non_ca_cars.drop(columns=['Ticket number', 'Issue time', 'Meter Id', \n",
    "                                        'Marked Time', 'VIN', 'Make', 'Body Style', \n",
    "                                        'Color', 'Location', 'Route', 'Agency', 'Violation code', \n",
    "                                        'Violation Description', 'Fine amount', 'Latitude', 'Longitude'])\n",
    "\n",
    "non_ca_cars = non_ca_cars.dropna(subset=['Plate Expiry Date'])\n",
    "non_ca_cars.loc[:,\"Plate Expiry Date\"] = non_ca_cars[\"Plate Expiry Date\"].astype(int)\n",
    "non_ca_cars.loc[:,\"Plate Expiry Date\"] = non_ca_cars[\"Plate Expiry Date\"].astype(str)\n",
    "\n",
    "# Re-format all dates to match\n",
    "non_ca_cars.loc[:,'Plate Expiry Date Formatted'] = pandas.to_datetime(\n",
    "    non_ca_cars['Plate Expiry Date'], format='%Y%m', errors='coerce').dropna()\n",
    "\n",
    "\n",
    "non_ca_cars.loc[:,'Issue Date Formatted'] = pandas.to_datetime(\n",
    "    non_ca_cars['Issue Date'], format='%Y-%m', errors='coerce').dropna()\n",
    "\n",
    "# Again, drop extra columns\n",
    "non_ca_cars = non_ca_cars.drop(columns=['Plate Expiry Date', 'Issue Date'])\n",
    "\n",
    "expired_plates = len(non_ca_cars[non_ca_cars['Issue Date Formatted'] > non_ca_cars['Plate Expiry Date Formatted']])\n",
    "\n",
    "not_expired_plates = len(non_ca_cars[non_ca_cars['Issue Date Formatted'] < non_ca_cars['Plate Expiry Date Formatted']])\n",
    "\n",
    "print(\"Percentage of out of state cars that received a citation while their license plate was expired:\")\n",
    "print(str(expired_plates/(expired_plates+not_expired_plates)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage in state cars that received a citation while their license plate was expired:\n",
      "22.02060669282623\n"
     ]
    }
   ],
   "source": [
    "# And now, the in state cars:\n",
    "\n",
    "ca_cars = df[df['RP State Plate'] == 'CA']\n",
    "ca_cars['Ticket number'].count()\n",
    "\n",
    "# Drop extra columns\n",
    "ca_cars = ca_cars.drop(columns=['Ticket number', 'Issue time', 'Meter Id', 'Marked Time', 'VIN', 'Make', 'Body Style', 'Color', 'Location', 'Route', 'Agency', 'Violation code', 'Violation Description', 'Fine amount', 'Latitude', 'Longitude'])\n",
    "\n",
    "ca_cars = ca_cars.dropna(subset=['Plate Expiry Date'])\n",
    "ca_cars.loc[:,\"Plate Expiry Date\"] = ca_cars[\"Plate Expiry Date\"].astype(int)\n",
    "ca_cars.loc[:,\"Plate Expiry Date\"] = ca_cars[\"Plate Expiry Date\"].astype(str)\n",
    "\n",
    "\n",
    "# Re-format all dates to match\n",
    "ca_cars.loc[:,'Plate Expiry Date Formatted'] = pandas.to_datetime(\n",
    "    ca_cars['Plate Expiry Date'], format='%Y%m', errors='coerce').dropna()\n",
    "\n",
    "ca_cars.loc[:,'Issue Date Formatted'] = pandas.to_datetime(\n",
    "    ca_cars['Issue Date'], format='%Y-%m', errors='coerce').dropna()\n",
    "\n",
    "# Again, drop extra columns\n",
    "ca_cars = ca_cars.drop(columns=['Plate Expiry Date', 'Issue Date'])\n",
    "\n",
    "expired_plates = len(ca_cars[ca_cars['Issue Date Formatted'] > ca_cars['Plate Expiry Date Formatted']])\n",
    "\n",
    "not_expired_plates = len(ca_cars[ca_cars['Issue Date Formatted'] < ca_cars['Plate Expiry Date Formatted']])\n",
    "\n",
    "print(\"Percentage in state cars that received a citation while their license plate was expired:\")\n",
    "print(str(expired_plates/(expired_plates+not_expired_plates)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
